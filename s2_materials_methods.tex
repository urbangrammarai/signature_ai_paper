\section{Materials and Methods}
\label{sec:matmet}

In this section we present the materials used in the research - the British spatial signatures used as to generate labels for individual chips and Sentinel 2 satellite imagery - and methods designed to unpack the role of geography in image-based deep learning.

\subsection{Materials}

The whole research uses only two data inputs, one representing the "ground truth" we are aiming to predict using neural networks and the other representing the satellite imagery. While the latter does not need a lot of introduction, the British spatial signatures used as the labels need to be explained further.

\subsubsection{British Spatial Signatures}
% 500 words

Spatial signatures are a way of classification of space covering entirety of a case study area. They are defined as \textit{"a characterisation of space based on form and function designed to understand urban environments"} \citep{dab_mf_2021a} and the definition already points at the clear distinction between signatures and traditional Land Use / Land Cover (LULC) classifications. Taking the example of CORINE (REF) as a representative of LULC, it has 44 distinct classes, out of which 2 cover urban form and other 6 can be loosely related to urban areas\footnote{Continuous urban fabric, Discontinuous urban fabric; Construction sites, Green urban areas, Sport and leisure facilities, Industrial or commercial units, Road and rail networks and associated land, Port areas}. A similar situation is with recently released global LULC datasets. ESA's WorldCover project distinguishes 11 classes of which one is urban (Built-up) REF. ESRI's Land cover has 9 classes where one is \textit{Built Area} and the rest covers unbuilt areas. This ratio of built vs unbuilt classes is typical but not very suited for research applications focusing on urban environments. Spatial signatures tend to flip this ratio as they are primarily classifying urban space.

There are two key main concepts embedded in spatial signatures delivering urban-focused classification. The first one is the spatial unit called the enclosed tessellation cell (ETC). To derive ETCs, we first generate \textit{enclosures}, a space fully enclosed by a set of barriers (roads, railways, rivers, coastline). ETCs are then a result of Voronoi tessellation based on building footprint polygons. The resulting spatial unit has adaptive granularity reflecting the scale of each individual urban pattern. The second is the selection of characters describing each ETC. We measure form and function, both primarily urban phenomena.

% We may want to add a figure explaining ETCs here.

British spatial signatures are one application of the concept of spatial signatures in the context of Great Britain REF SDATA. It divides the space into 16 data-driven classes listed in the table REF TABLE. Out of these 16 classes, 9 are entirely urban, 4 are peripheral and only 3 are classifying countryside, completely flipping the ratio of built vs unbuilt classes known from LULC.


\begin{tabular}{lrrrr}
    \caption{\label{tab:sig_types}Classes of British spatial signatures and their coverage in terms of area and a number of ETCs.}\\
    \toprule
    {} &        total area (sq.km) &  total ETC count &  percentage of area &  percentage of ETCs \\
    signature\_type                       &             &         &            &             \\
    \midrule
    Countryside agriculture              & 93,856.1 & 3,022,385 &         41 &          21 \\
    Accessible suburbia                  &  2,244.5 & 1,962,830 &          1 &          14 \\
    Dense residential neighbourhoods     &    957.2 &   502,835 &          0 &           3 \\
    Connected residential neighbourhoods &    565.4 &   374,090 &          0 &           3 \\
    Dense urban neighbourhoods           &    570.6 &   238,639 &          0 &           2 \\
    Open sprawl                          &  5,081.5 & 2,561,211 &          2 &          18 \\
    Wild countryside                     & 91,306.3 &   595,902 &         40 &           4 \\
    Warehouse/Park land                  &  2,462.4 &   707,211 &          1 &           5 \\
    Gridded residential quarters         &    261.2 &   209,959 &          0 &           1 \\
    Urban buffer                         & 31,588.8 & 3,686,554 &         14 &          25 \\
    Disconnected suburbia                &    708.9 &   564,318 &          0 &           4 \\
    Local urbanity                       &    231.1 &    86,380 &          0 &           1 \\
    Concentrated urbanity                &      7.8 &     1,390 &          0 &           0 \\
    Regional urbanity                    &     76.4 &    21,760 &          0 &           0 \\
    Metropolitan urbanity                &     16.5 &     3,739 &          0 &           0 \\
    Hyper concentrated urbanity          &      2.2 &       264 &          0 &           0 \\
    \bottomrule
\end{tabular}



% add figure



\subsubsection{Sentinel 2 imagery}

% 250 words

The second data input used in this research is satellite imagery provided by the Sentinel 2 mission. Specifically, we use the pre-processed cloud-free mosaic of Sentinel 2 released by {REF https://www.sciencedirect.com/science/article/pii/S2352340920306314}. The mosaic provides pixel-level composite based on imagery for the period January 2017- December 2018 at an original resolution of 10 meters per pixel. While Sentinel 2 captures many spectral bands beyond traditional visible red, green and blue (RGB),  this research uses only RGB bands due to its employment of pre-trained neural networks stemming from non-satellite imagery that is composed only of RGB. The exclusion of other bands may be seen as a limiting factor of the work, but we believe that, as with other aspects that will be discussed later, it efficiently illustrates the \textit{lower bound} of the performance of presented method and can be only improved with addition of further spectral bands or other data (e.g. synthetic-aperture radar imagery).

Another notable aspect of the Sentinel 2 imagery is the resolution. Ten meters per pixel may be enough to distinguish LULC classes as shown by the research project discussed above. However, there is a question whether it is enough in urban environments. Individual buildings often don't stretch beyond the spatial extent of two pixels, which is severely limiting what we can \textit{see} on the image, as illustrated on a fig REF. While other data sources may provide better resolution (REFS), potentially affecting the performance of the model, this research is bound within the limits of \textit{open data}, where Sentinel 2 is the best offering to date.


\subsection{Methods}

% 250 to explain the overarching experiments

-

\subsubsection{Chip size}

% 500 words

% add figure of sentinel 2 imagery and chip size


\subsubsection{Data (spatial) augmentation}

% Sliding

% 250 words

\subsubsection{Model architecture}

% 500 words

% Overall content of the section

% NN architecture: not of particular interest, hence we pick EfficientNet
% (but we show in appendix a brief comparison why)
Appendix \ref*{sec:appendixA} shows a brief comparison of several standard neural network architectures.

% We define our challenge as an image classification task and use competing
% alternatives to explore which one performs best. Each of them imply
% geographically interesting trade-off's

% Standard image classification

% Multi-output regression

% Spatial modelling of probabilities

\subsubsection{Performance metrics}

% 500 words

% Traditional non-spatial

% Explicitly spatial metrics
%% Why
%% Which ones
%% Why those? (ideally link to Miguel's paper suggestions)

\subsubsection{Summarizing experiments}

% 250 words

% explanation of regression approach